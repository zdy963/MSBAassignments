---
title: "Assignmet 1"
author: "Dongyu Zhang"
date: "2018/12/3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(forecast)
library(fpp2)
options(scipen = 200)
```

## Question 1
Reading monthly Australian retail data
```{r}
retaildata <- readxl::read_excel("../data/retail.xlsx", skip=1)
```
<br>Have a look of Newspaper and book retailing turnover in Victoria
```{r}
myts <- ts(retaildata[,"A3349639C"],
  frequency=12, start=c(1982,4))

autoplot(myts)
```
From the plot of turnover over time, we can found that there is a significant seasonality and seems to have a trend of increase.<br>
Then we have a look at seasonal plot:
```{r}
ggseasonplot(myts)
```
Seasonal plot strongly support our seasonality assumption with a rapid increase at the end of each year, especially in Decemenber.<br>
Now, let's have a look of seasonal subseries plot.
```{r}
ggsubseriesplot(myts)
```
Through this plot, we can find out there is a cycle within each month. Turnover will increase really rapid at the begining of the month but decrease at around 10th each month and increase again.<br>
Have a look of lag plot:
```{r}
gglagplot(myts)
```
```{r}
ggAcf(myts,lag.max = 80)
```
The ACF plot shows a significant seasonality and trend of decreasing.<br>
To summarize, we can say that the turnover for Newspaper and book retailing in Victoria has sesonality, higher at the end of a month and a year, and trend of increasing.


## Question 2
Autocorrelation Functions is defined as follow:<br>
$\rho_h=Corr(x_t,x_{t+h})=\frac{\gamma_h}{\gamma_0}$<br>
It shows the similarity between different time under different lag.
<br><br>
There are two kinds of plot in this grid. For plot 1 and 3, they have a strong tendency of increase or decrease. For plot 2 and 4, they shows some kind of cycle.<br>
ACF plot A and C, looks like their series have a cycle and plot A reveals a higher covariance, compairing to plot C. <br>
So, plot A should be plot 2's ACF plot and C should be 4's ACF plot.<br>
On the other hand, plot B and D demonstrate a trends with, however, plot D higher in covariance. <br>
Thus, plot B should be plot 1 and plot D should be plot 3.

## Question 3
```{r}
ddj <- diff(dj)
autoplot(ddj)
ggAcf(ddj,lag.max = 80)
```
According to the time series' plot, it does look like white noise. The ACF plot further proves this assumption for most of acf for Dow Jones Index lies within the limit, confirming that the data are white noise.

## Question 4
### a.
From the trend plot, we can find out that number of persons in the civilian labour force in Australia steadily increasing.<br>
Seasonal plot reveals the strong seasonality in data.
Seasonal component plot shows that number of people in civilian labour force is the very low in Janurary and, however, increasing very fast to a peak in March after which starts to drop slowly and reachs bottom and at August. Then fluctuate from September to December and reaches the peak at December.
### b.
No. From remainder plot, we can find out that there are many significant negative records around 1991 and 1992, which means the estimation did not capture the decreasement in 1991 and 1992.

## Question 5
### Caculating average
$$
\begin{aligned}
\mu &= E(x_t)=E(U_1sin(2\pi\omega t)+U_2cos(2\pi\omega t))\\
&= U_1E(sin(2\pi\omega t)) + U_2E(cos(2\pi\omega t))\\
&= 0\times E(sin(2\pi\omega t)) + 0\times E(cos(2\pi\omega t)) \\
&= 0
\end{aligned} 
$$
Average of $x_t$ = $E(x_t)=\mu=0$ is constant.
### Caculating covariance
$$
\begin{aligned}
\gamma_h =&\; Cov(x_t,x_{t+h})\\
=&\; Cov(U_1sin(2\pi\omega t)+U_2cos(2\pi\omega t),U_1sin(2\pi\omega (t+h))+U_2cos(2\pi\omega (t+h)))\\
=&\; Cov(U_1sin(2\pi\omega t),U_1sin(2\pi\omega (t+h))) + Cov(U_1sin(2\pi\omega t),U_2cos(2\pi\omega (t+h))) + \\
&\;Cov(U_2cos(2\pi\omega t),U_1sin(2\pi\omega (t+h))) + Cov(U_2cos(2\pi\omega t),U_2cos(2\pi\omega (t+h))) \\
=&\;sin(2\pi\omega t)\times sin(2\pi\omega (t+h))\times Var(U_1) + \\
&\; sin(2\pi\omega t)\times cos(2\pi\omega (t+h))\times Cov(U_1,U_2) + \\
&\; cos(2\pi\omega t)\times sin(2\pi\omega (t+h))\times Cov(U_1,U_2) + \\
&\; cos(2\pi\omega t)\times cos(2\pi\omega (t+h))\times Var(U_2) \\
=&\; sin(2\pi\omega t)\times sin(2\pi\omega (t+h))\times\sigma^2 + 0 + 0 + cos(2\pi\omega t)\times cos(2\pi\omega (t+h))\times \sigma^2\\
=&\;cos(2\pi\omega (t+h) - 2\pi\omega t) \times \sigma^2= cos(2\pi\omega h)\times \sigma^2
\end{aligned} 
$$
The covariance for $x_t$ only relates to $h$, the lag.
<br><br>
In such case, $x_t$ is weakly stationary. It's autocovariance function is:<br>
$\gamma_{t,t+h}= \sigma^2cos(2\pi\omega h)$

### Correlation function
$$
\begin{aligned}
\rho_h&=Corr(x_t,x_{t+h})=\frac{\gamma_h}{\gamma_0}\\
&=\frac{\sigma^2cos(2\pi\omega h)}{\sigma^2}\\
&= cos(2\pi\omega h)
\end{aligned}
$$

## Question 6
### Calculate autocovariance function
For $lag=0$:
$$
\begin{aligned}
\gamma_{t,\,t}&=Cov(x_t,x_{t})\\
&=Cov(\sum\limits_{j=0}^{\infty} 0.5^ja_{t-j}\,,\sum\limits_{j=0}^{\infty} 0.5^ja_{t-j})\\
&=\sum\limits_{j=0}^{\infty} 0.5^{2j}Cov(a_{t-j},a_{t-j})\\
&=\sum\limits_{j=0}^{\infty} 0.5^{2j}\times2.25\\
&=2.25\times\frac{1}{1-0.25}\\
&=3
\end{aligned}
$$
For $lag=h$
$$
\begin{aligned}
\gamma_{t,\,t+h}&=Cov(x_t,x_{t+h})\\
&=Cov(\sum\limits_{j=0}^{\infty} 0.5^ja_{t-j}\,,\sum\limits_{j=0}^{\infty} 0.5^ja_{t+h-j})\\
&=\sum\limits_{j=0}^{\infty} 0.5^{2j}Cov(a_{t-j},a_{t+h-j})\\
&=\sum\limits_{j=0}^{\infty} 0.5^{2j}\times0\\
&=0
\end{aligned}
$$
We can easily find out that $x_t$ is weakly stationary.
### Calculate autocorrelation function
$$
\begin{aligned}
\rho_h&=Corr(x_t,x_{t+h})=\frac{\gamma_h}{\gamma_0}\\
&=\frac{0}{3}=0
\end{aligned}
$$

## Question 7
```{r}
hwi.new <- read.table('../data/hawaii-new.dat')
```

### a.
```{r}
total <- ts(hwi.new$V2,frequency=12, start=c(1970,1))
west <- ts(hwi.new$V3,frequency=12, start=c(1970,1))
east <- ts(hwi.new$V4,frequency=12, start=c(1970,1))

autoplot(total,legendLab="total",series="Total") +
  autolayer(west,series="East-bound")+
  autolayer(east,series="West-bound")+
  xlab("Year") +
  ylab("Number of people")
```
From the above plot, we can find a generally increasing trend to both east and west bound so as total. However, around 1992, west-bound faced some kinds of accident, which made number of tourist started to decrease. Also, the fluctuation from different side of the bound. For east-bound, specifically, the variance is really small before 1985 but rapidly increase after 1985.


### b.
```{r}
total.log = log(total)
autoplot(total.log)
```
Using log transformation, increasing trend is more significant. Also, we can find that the increasing speed becomes slower with the increasement of time.

### c.
From the plot we draw in question b, there seems to have a quadratic relationship between log(total) and time. Let's try linear, quadratic and cubic one by one.
```{r}
total.linear = tslm(total.log~trend)
total.quadratic = tslm(total.log~trend+I(trend^2))
total.cubic = tslm(total.log~trend+I(trend^2)+I(trend^3))

par(mfrow=c(3,2))
plot(total.log,ylab="Number of people",main="Linear fit")
lines(as.vector(time(total.log)),total.linear$fitted,col="blue")

plot(total.linear$residuals,ylab="Residuals",main="Linear de-trended series",col="blue")
lines(as.vector(time(total.log)),total.linear$res,col="blue")
abline(h=0)

plot(total.log,ylab="Number of people",main="Quadratic fit")
lines(as.vector(time(total.log)),total.quadratic$fitted,col="blue")

plot(total.quadratic$residuals,ylab="Residuals",main="Quadratic de-trended series",col="blue")
lines(as.vector(time(total.log)),total.quadratic$res,col="blue")
abline(h=0)

plot(total.log,ylab="Number of people",main="Cubic fit")
lines(as.vector(time(total.log)),total.cubic$fitted,col="blue")

plot(total.cubic$residuals,ylab="Residuals",main="Cubic de-trended series")
lines(as.vector(time(total.log)),total.cubic$res,col="blue")
abline(h=0)
```

Cubic seems to have the same estimate error with quadratic fit and quadratic model have smaller residuals than linear model. So, quadratic model is the best model among these three methods.

### d.
```{r}
total.season.lm = tslm(total.log~trend + season-1)
total.season.quad = tslm(total.log~trend+I(trend^2) + season-1)

par(mfrow=c(2,2))
plot(total.log,ylab="Number of people",main="Trend-seasonal model")
lines(as.vector(time(total.log)),total.season.lm$fitted,col="blue")

plot(total.season.lm$residuals,ylab="Residuals",main="de-trend-de-seasoned series",col="blue")
# lines(as.vector(time(total.log)),total.seasonal$res,col="blue")
abline(h=0)

plot(total.log,ylab="Number of people",main="Trend-seasonal model")
lines(as.vector(time(total.log)),total.season.quad$fitted,col="blue")

plot(total.season.quad$residuals,ylab="Residuals",main="de-trend-de-seasoned series",col="blue")
# lines(as.vector(time(total.log)),total.seasonal$res,col="blue")
abline(h=0)

summary(total.season.lm)
summary(total.season.quad)
```
From coefficients, both trend and season have significant on model.<br>
Comparing to linear model, quadratic model also shows a stronger estimation on trend-season model. From the de-trend-de-seasoned plot, we can see that quadratic model have a more balanced residual as it did in trend-only model, which shows it has better estimation on the data. Coefficients also support this asumption, having smaller RSE and higher Multiple R-squared.

### e.
```{r}
predi <- forecast(total.season.quad,h=12)
# predi.2 <- window(predi,start=1993,end=1996)
autoplot(predi, PI=FALSE) 
  # autolayer(predi,col='blue')
```














